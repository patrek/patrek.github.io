---
date: "2025-12-14T00:00:00-05:00"
draft: true
title: "Développer pour le cloud (distribué)"
description: "Considérations pour le développement d'une application cloud native"
featured_image: "/images/dev-for-cloud.png"
tags: ["cloud", "aws", "azure", "gcp", "multiples instances", "devops", "architecture", "design patterns"]
summary: "Une liste de considérations et pratiques pour le développement d'une application cloud native."
toc: true
---

= Développer pour le cloud (distribué)
:sectnums:
:toc: left

== Introduction

L'idée de cet article m'est venue après ma publication en début d'année sur les éléments à considérer quand on link:{{< ref "green-field.adoc" >}}[démarre un projet de développement] et en discutant avec des collègues qui commençaient à apprendre l'utilisation de plateformes cloud.

Les applications sont maintenant souvent déployées dans des environnements cloud distribués, que ce soit par l'intermédiaire de Kubernetes, de services managés ou de fonctions serverless.
Plusieurs fournisseurs cloud majeurs, tels qu'AWS, Azure et GCP, offrent des services pour héberger ces applications.

Le développement d'applications qui seront déployés dans des environnements cloud distribués nécessite de prendre en considérations plusieurs aspects spécifiques.
Voici une liste de pratiques et de considérations clés pour développer des applications cloud natives.

Pour les fins de cet article, nous énoncerons principalement des considérations pour les services à durée de vie prolongée.
La plupart de ces considérations s'appliquent également aux fonctions serverless et aux applications événementielles.

De plus, pour faciliter la lecture, fournisseur cloud sera utilisé de manière interchangeable pour désigner les environnements cloud distribués et inclura le déploiement par Kubernetes.

== Multiples instances pour rendre le même service

====
Plusieurs clones, une seule mission
====

La considération la plus importante est que votre application doit être conçue pour fonctionner dans un environnement où plusieurs instances de l'application peuvent être exécutées simultanément.
Cela signifie que votre application ne doit pas dépendre d'un état local ou de ressources spécifiques à une instance.

Que ce soit pour scaler horizontalement (ajouter plus d'instances) ou pour la résilience (redémarrer une instance défaillante), parce que le nombre d'instances change en fonction de la charge réelle ou anticipée, en fonction de l'heure, etc., votre application doit être capable de gérer plusieurs instances sans conflit.

Elle sera aussi probablement démarrée sans intervention humaine. Vous devez donc conserver cet aspect en tête lors de la conception et du développement de votre application.

== Architecture derrière un load balancer

====
Comme une répartitrice d'appels en centre de services: chaque requête est envoyée au bon département — facturation, support, ou comptes — selon ce qu'elle demande.
====

Dans la plupart des cas, les instances de votre application seront déployées derrière un load balancer (équilibreur de charge).
Le load balancer distribue le trafic entrant entre les différentes instances de votre application.
Cela signifie que votre application doit être capable de prendre le relais d'une requête sans avoir répondu à la requête précédente dans le workflow.

Dans les architectures modernes, le load balancer ou l'API Gateway peut aussi router vers des services différents selon la requête:

* Par chemin (path-based routing), ex.: `/api/users` → service Utilisateurs, `/api/orders` → service Commandes
* Par hôte (host-based routing), ex.: `api.example.com` → API, `static.example.com` → ressources statiques
* Par en-tête ou version d'API (header/version routing), ex.: `X-Client: mobile` ou `Accept: application/vnd.company.v2+json`
* Par méthode ou port (rare), selon les contraintes techniques

Conséquence côté développement:

* Évitez les hypothèses d'état de session local, car une requête peut arriver à un autre service ou une autre instance
* Respectez des contrats d'API clairs et versionnés
* Propager les identifiants de corrélation pour tracer la requête à travers plusieurs services

== Externaliser la configuration

====
Externaliser la configuration, c'est comme insérer une carte SIM dans un téléphone : même appareil, réglages adaptés au réseau. En changeant de SIM, on peut aussi changer de fournisseur — Bell, Vidéotron, Orange — sans toucher au téléphone lui-même.
====

Un aspect important du développement pour le cloud est de séparer la configuration de l'application du code lui-même. Cela permet de déployer la même application dans différents environnements (développement, test, production) avec des configurations différentes.
Cela permet aussi de modifier la configuration sans avoir à recompiler l'application.

Une pratique très courante est d'utiliser des variables d'environnement pour fournir la configuration à l'application.

Les différents fournisseurs cloud offrent aussi un service d'externalisation de la configuration, comme AWS Systems Manager Parameter Store, Azure App Configuration ou GCP Secret Manager.
Ces services permettent de stocker et de gérer la configuration de manière sécurisée et centralisée.
Par contre, vous devrez adapter votre application pour qu'elle puisse récupérer la configuration à partir de ces services.

Le choix final dépend de si vous prévoyez déployer votre application dans un seul fournisseur cloud ou dans plusieurs.

== Feature flags et configuration dynamique

====
Les feature flags, c'est comme les scènes post-crédits Marvel: on peut les activer pour certains, les cacher pour d'autres, et les couper net si ça tourne mal. Zéro recompilation, juste un interrupteur.
====

Les feature flags (drapeaux de fonctionnalités) permettent d'activer ou désactiver des fonctionnalités sans redéployer l'application. C'est particulièrement utile dans un environnement cloud pour :

* *Déploiements progressifs* : Activer une nouvelle fonctionnalité pour un pourcentage d'utilisateurs ou certains groupes d'utilisateurs
* *A/B testing* : Tester différentes versions d'une fonctionnalité
* *Kill switch* : Désactiver rapidement une fonctionnalité problématique en production sans redéployer
* *Environnements spécifiques* : Activer des fonctionnalités seulement dans certains environnements

Des outils comme LaunchDarkly, Unleash, Split.io, ou AWS AppConfig peuvent être utilisés pour gérer les feature flags.

== Gestion des secrets

====
Mettre des secrets dans le code source, c'est comme cacher la clé de la maison sous le paillasson : tout le monde sait où chercher. Utilisez un vrai coffre-fort.
====

Ne jamais stocker des secrets (mots de passe, clés API, certificats) directement dans le code ou dans les fichiers de configuration versionnés.

Utilisez plutôt :

* *Services cloud dédiés* : AWS Secrets Manager, Azure Key Vault, GCP Secret Manager
* *Orchestrateur* : Kubernetes Secrets (avec encryption at rest activée)
* *Outils tiers* : HashiCorp Vault, SOPS

Ces solutions offrent :

* Encryption des secrets au repos et en transit
* Contrôle d'accès granulaire
* Rotation automatique des secrets
* Audit des accès


== Sauvegarde de fichiers intermédiaires

====
Écrire sur le disque local en cloud, c'est laisser vos notes sur la table du café: ça marche… jusqu'au ménage.
====

Imaginons une application qui génère un rapport (PDF, Excel, etc.) à partir de données fournies par l'utilisateur.

Dans un scénario "classique", l'application pourrait générer le rapport sur le disque dur local de l'instance, puis le rendre disponible pour téléchargement.

Par contre, dans un environnement à multiple instance, il faut mettre ce fichier soit dans un stockage partagé, un volume réseau, ou, au pire, la base de données.

Les fournisseurs offrent des services de stockage, comme AWS S3, AWS EFS, Azure Blob Storage, Azure Files, GCP Cloud Storage ou GCP Filestore, qui peuvent être utilisés pour stocker ces fichiers intermédiaires.


== Tâches périodiques / Cron Job

====
Les crons en multi-instances, c'est comme des réveils en colocation: un seul suffit, sinon tout le monde se lève à 3h.
====

Les tâches périodiques, comme l'envoi de courriel de rappel, la création de rapports ou la purge de données sont fréquentes dans les applications.

Dans un environnement cloud distribué, il est important de s'assurer que ces tâches ne sont pas exécutées simultanément par plusieurs instances de l'application.

Pour y arriver, il faut réfléchir à une façon de synchroniser l'exécution de ces tâches. Plusieurs approches sont possibles :

* Utiliser un service de planification externe, comme AWS CloudWatch Events, Azure Logic Apps ou GCP Cloud Scheduler, pour déclencher les tâches périodiques.
* Utiliser un mécanisme de verrouillage distribué, comme une entrée dans une base de données ou un service de cache distribué (Redis, Memcached) pour s'assurer qu'une seule instance exécute la tâche à un moment donné.
* Utiliser une bibliothèque de planification comme Quartz Scheduler ou autre similaire.

Il peut être intéressant de développer des urls pour lancer des tâches spécifiques, qui peuvent être appelées par le service de planification externe ou par un job interne avec un verrouillage distribué.
Des urls complémentaires pour obtenir le statut des tâches peuvent aussi être utiles pour le monitoring.

L'important, c'est de faire en sorte que les tâches périodiques soient exécutées de manière fiable et sans conflit entre les différentes instances de l'application.

== Gestion de l'état et des sessions

====
Les sessions en cloud, c'est un vestiaire: on présente son ticket et on retrouve son manteau, peu importe la porte d'entrée ou le préposé.
====

Dans un environnement distribué avec plusieurs instances, la gestion de l'état utilisateur (sessions) devient critique. Si un utilisateur se connecte à une instance et que sa prochaine requête est routée vers une autre instance, l'application doit pouvoir récupérer l'état de la session.

Plusieurs approches existent :

* *Sessions stateless* : Utiliser des tokens JWT (JSON Web Tokens) qui contiennent toutes les informations nécessaires. Le client transmet le token à chaque requête. Il peut le transmettre par header, par cookie, ou dans le corps de la requête.
* *Cache distribué* : Stocker les sessions dans un cache distribué comme Redis ou Memcached, accessible par toutes les instances.
* *Sticky sessions* : Configurer le load balancer pour router toujours le même utilisateur vers la même instance (moins recommandé car crée des dépendances et ne fonctionnera pas si l'instance est arrêtée).
* *Base de données* : Stocker les sessions dans la base de données (moins performant mais plus simple).

La meilleure approche dépend de vos besoins spécifiques, mais les sessions stateless ou le cache distribué sont généralement préférés pour leur performance et leur scalabilité.

== Persistance et transactions de base de données

====
One pool to rule them all : les connexions doivent être partagées, les transactions idempotentes, et les erreurs gérées avec grâce. La base de données ne doit pas devenir votre Mordor.
====

Dans un environnement distribué, la gestion des transactions de base de données nécessite une attention particulière :

* *Connexions à la base de données* : Utilisez un pool de connexions pour optimiser l'utilisation des ressources. Configurez le nombre maximum de connexions en fonction du nombre d'instances.
* *Transactions distribuées* : Évitez les transactions distribuées (2PC - Two-Phase Commit) autant que possible, car elles sont complexes et réduisent la performance. Privilégiez le pattern Saga pour gérer les transactions sur plusieurs services.
* *Idempotence* : Concevez vos opérations de base de données pour être idempotentes, c'est-à-dire qu'elles produisent le même résultat même si elles sont exécutées plusieurs fois.
* *Retry et resilience* : Implémentez des mécanismes de retry pour gérer les échecs temporaires de connexion à la base de données.

=== Migrations de schéma de base de données

====
Migrer le schéma, c'est rénover sans fermer le magasin: on déplace les rayons, on garde les clients.
====

Les migrations de schéma dans un environnement distribué nécessitent une planification minutieuse :

* *Migrations forward-compatible* : Les changements doivent être compatibles avec l'ancienne version pendant le déploiement
* *Outils de migration* : Utilisez Flyway, Liquibase, ou des outils natifs (Alembic pour Python, migrate pour Go)
* *Blue-green deployments* : Pour les changements majeurs, déployez une nouvelle version complète
* *Migrations à l'arrêt vs au démarrage* : Décidez si les migrations s'exécutent avant ou pendant le déploiement
* *Rollback* : Préparez toujours un plan de rollback pour les migrations complexes
* *Testez en staging* : Testez toujours les migrations sur des données similaires à la production

=== Patterns pour les changements de schéma

* *Expand-Contract Pattern* :
  1. Expand : Ajoutez la nouvelle colonne/table
  2. Dual-write : Écrivez dans l'ancienne et la nouvelle structure
  3. Migrate : Migrez les anciennes données
  4. Contract : Supprimez l'ancienne structure

* *Versioning des API* : Quand les changements de schéma affectent l'API, utilisez le versioning (v1, v2)

== Mise en cache et performance

====
Le cache, c'est comme garder les documents importants sur votre bureau plutôt qu'au sous-sol : on accède vite à ce qu'on utilise souvent. Mais attention, il faut parfois faire le ménage pour éviter de travailler avec des versions périmées.
====

Le cache est crucial pour la performance dans un environnement cloud distribué :

=== Types de cache

* *Cache en mémoire local* : Rapide mais non partagé entre instances (Caffeine, Guava Cache)
* *Cache distribué* : Partagé entre toutes les instances (Redis, Memcached, Hazelcast)
* *CDN* : Pour les ressources statiques (CloudFront, Azure CDN, Cloud CDN)
* *HTTP caching* : Utilisez les headers HTTP (Cache-Control, ETag) pour le cache côté client

=== Stratégies de cache

* *Cache-aside* : L'application vérifie le cache, puis la base de données si nécessaire
* *Write-through* : Les données sont écrites dans le cache et la base de données simultanément
* *Write-behind* : Les données sont écrites dans le cache d'abord, puis dans la base de données de façon asynchrone
* *Invalidation* : Définissez des stratégies claires pour invalider le cache (TTL, événements)

=== Invalidation et nettoyage du cache

L'un des défis les plus importants avec le cache est de savoir quand le nettoyer ou l'invalider. Un cache obsolète peut causer des bugs difficiles à diagnostiquer.

* *TTL (Time-To-Live)* : Définissez une durée de vie maximale pour chaque entrée du cache. Après ce délai, l'entrée est automatiquement supprimée ou marquée comme expirée.
* *Invalidation par événement* : Lorsque des données sont modifiées dans la base de données, invalidez ou mettez à jour les entrées de cache correspondantes. Utilisez des event listeners ou des patterns pub/sub.
* *Cache tagging* : Associez des tags aux entrées de cache pour pouvoir invalider plusieurs entrées liées d'un coup (par exemple, toutes les entrées liées à un utilisateur spécifique).
* *Versioning* : Incluez une version dans la clé de cache. Quand vous déployez un changement de format, incrémentez la version pour invalider automatiquement les anciennes entrées.
* *Flush sélectif vs global* : Évitez de vider tout le cache (flush) sauf en cas d'urgence. Préférez l'invalidation ciblée pour maintenir les performances.
* *Cache warming* : Après un vidage ou au démarrage, préremplissez le cache avec les données les plus utilisées pour éviter une charge soudaine sur la base de données.

Considérations pour les environnements distribués :

* Si vous utilisez un cache distribué (Redis, Memcached), l'invalidation sera visible par toutes les instances
* Avec un cache local, vous devez propager les événements d'invalidation à toutes les instances (via pub/sub ou message queue)
* Documentez clairement votre stratégie d'invalidation pour chaque type de données cachées

=== Considérations importantes

* Attention au "thundering herd" : quand plusieurs instances tentent de recharger le même cache expiré simultanément
* Utilisez des clés de cache bien structurées pour faciliter l'invalidation ciblée
* Surveillez le taux de hit/miss du cache pour optimiser la configuration
* Loggez les invalidations de cache pour faciliter le debugging

== Considérations pour l'équipe devops

====
Le devops, c'est comme piloter un avion qu'on n'a pas construit : on a besoin d'instruments de bord clairs, de voyants qui s'allument au bon moment, et d'un manuel qui dit quoi faire si ça tourne mal.
====

L'équipe qui va déployer et gérer l'application a des besoins spécifiques qui doivent être pris en compte dès le début du développement. Ce sont des pratiques relativement simple à mettre en place en début de projet, mais qui peuvent sauver beaucoup de temps et d'efforts plus tard.

=== Observabilité : Logs, métriques et traces

====
Et quand l'avion a des problèmes, on devient détective : les logs racontent ce qui s'est passé dans le cockpit, les métriques montrent les tendances du vol, et les traces suivent la route à travers le ciel. Sans ces instruments, on enquête à l'aveugle dans le brouillard.
====

L'observabilité est cruciale dans un environnement cloud distribué où il peut être difficile de diagnostiquer les problèmes.

==== Logging structuré

* Utilisez un format de log structuré (JSON) pour faciliter la recherche et l'analyse.
* Incluez un identifiant de corrélation (correlation ID) dans chaque log pour tracer une requête à travers plusieurs services et instances.
* Centralisez vos logs dans un système comme AWS CloudWatch, Azure Monitor, GCP Cloud Logging, ELK Stack (Elasticsearch, Logstash, Kibana), Datadog ou Loki.
* Évitez de logger des informations sensibles (mots de passe, tokens, données personnelles).
* Si possible, utilisez des bibliothèques de logging qui supportent la reconfiguration dynamique du niveau de log (DEBUG, INFO, WARN, ERROR) sans redémarrer l'application.

==== Métriques

* Exposez des métriques sur la santé et la performance de votre application (temps de réponse, nombre de requêtes, taux d'erreur, utilisation CPU/mémoire).
* Utilisez des outils comme Prometheus, Grafana, ou les services cloud natifs pour collecter et visualiser ces métriques.
* Configurez des alertes basées sur ces métriques pour être notifié des problèmes.

==== Tracing distribué

* Implémentez le tracing distribué avec des outils comme Jaeger, Zipkin ou AWS X-Ray pour suivre le parcours d'une requête à travers vos différents services.
* Utilisez OpenTelemetry comme standard pour instrumenter votre application.

=== Health checks et readiness probes

====
Les probes, c'est le test du micro avant le concert: on vérifie qu'on est prêt avant de monter le son.
====

Les orchestrateurs comme Kubernetes et les load balancers ont besoin de savoir si une instance de votre application est en bonne santé et prête à recevoir du trafic.

* *Liveness probe* : Indique si l'application est vivante et fonctionne. Si elle échoue, l'orchestrateur redémarre l'instance.
* *Readiness probe* : Indique si l'application est prête à recevoir du trafic. Par exemple, si les connexions à la base de données ne sont pas encore établies, l'instance n'est pas prête.
* *Startup probe* : Pour les applications qui prennent du temps à démarrer, évite que la liveness probe ne tue l'application prématurément.

Implémentez des endpoints HTTP dédiés (par exemple `/health` et `/ready`) qui retournent le statut approprié.

=== Graceful shutdown

====
Fermer en douceur, c'est dire au revoir avant de raccrocher: on termine la phrase, puis on coupe.
====

Lorsqu'une instance de votre application est arrêtée (mise à jour, scaling down, etc.), elle doit se terminer proprement :

* Arrêter d'accepter de nouvelles requêtes
* Terminer le traitement des requêtes en cours
* Fermer proprement les connexions aux bases de données et aux services externes
* Libérer les ressources

Implémentez un signal handler (SIGTERM) pour gérer l'arrêt gracieux de votre application. La plupart des orchestrateurs envoient un SIGTERM avant de forcer l'arrêt avec SIGKILL.

=== Gestion des dépendances et vulnérabilités

====
Faites votre inventaire comme chez Home Alone: vérifiez les pièges, ne laissez pas d'entrées faciles.
====

La gestion proactive des dépendances est cruciale pour la sécurité et la stabilité :

* *Scan régulier* : Utilisez des outils comme Dependabot, Snyk, ou OWASP Dependency-Check pour identifier les vulnérabilités dans vos dépendances
* *Mises à jour automatisées* : Configurez des pull requests automatiques pour les mises à jour de sécurité
* *Versioning sémantique* : Respectez le versioning sémantique pour vos propres bibliothèques
* *Lockfiles* : Utilisez des fichiers de verrouillage (package-lock.json, Pipfile.lock, go.sum) pour garantir la reproductibilité
* *Audit régulier* : Faites des audits de sécurité réguliers de vos dépendances

=== CI/CD et pipelines de déploiement

====
Le pipeline, c'est la chaîne de montage: on sort des versions fiables, pas des prototypes du lundi matin.
====

L'automatisation du déploiement est essentielle pour le cloud. Elle sera probablement en partie la responsabilité de l'équipe devops, mais les développeurs doivent aussi en tenir compte.

* *Intégration continue* : Exécutez les tests automatiquement à chaque commit (GitHub Actions, GitLab CI, Jenkins, CircleCI).
* *Tests* : Incluez des tests unitaires, d'intégration, et end-to-end dans votre pipeline.
* *Build d'images* : Automatisez la création des images de conteneur.
* *Scan de sécurité* : Intégrez le scan de sécurité des images et des dépendances dans le pipeline.
* *Déploiement progressif* : Utilisez des stratégies comme blue/green deployment, canary deployment, ou rolling updates pour minimiser les risques.
* *Rollback automatique* : Configurez un rollback automatique si les health checks échouent après un déploiement.
* *Infrastructure as Code* : Gérez votre infrastructure avec Terraform, CloudFormation, Pulumi, ou ARM templates.


=== Conteneurisation et images

====
Un bon conteneur, c'est une valise bien rangée: légère, sécurisée, et sans le tag ‘latest' perdu à l'aéroport.
====

La conteneurisation est quasi-universelle dans le déploiement cloud :

* *Images légères* : Utilisez des images de base minimales (Alpine, distroless) pour réduire la taille et la surface d'attaque.
* *Multi-stage builds* : Utilisez des builds multi-étapes pour séparer la compilation de l'exécution et réduire la taille finale.
* *Scan de sécurité* : Scannez vos images pour détecter les vulnérabilités (Trivy, Snyk, Clair).
* *Versioning* : Versionnez vos images et évitez d'utiliser le tag `latest` en production.
* *Non-root user* : Exécutez vos conteneurs avec un utilisateur non-root pour la sécurité.
* *Pipelines* : Automatisez la construction, le test et le déploiement de vos images via des pipelines CI/CD.

=== Optimisation des coûts

====
Le cloud facture comme un taxi: laissez le compteur tourner, et la note grimpe. Mettez des limites.
====

Le cloud peut devenir coûteux si on ne fait pas attention :

* *Auto-scaling intelligent* : Configurez l'auto-scaling basé sur des métriques réelles (CPU, mémoire, nombre de requêtes).
* *Right-sizing* : Choisissez la taille d'instance appropriée pour votre charge de travail. Ne sur-provisionnez pas.
* *Utilisation de spot instances* : Pour les charges de travail non-critiques ou les environnements de test, utilisez des instances spot/préemptibles.
* *Shutdown automatique* : Arrêtez les environnements de développement et de test en dehors des heures de travail.
* *Monitoring des coûts* : Utilisez les outils de monitoring des coûts fournis par votre cloud provider.

=== Gestion des ressources et limites

====
Les ressources, c'est le budget calorique: trop peu, on cale; trop, on somnole. Trouvons le bon dosage.
====

Définir correctement les ressources allouées à votre application est essentiel :

* *Requests et Limits* : Dans Kubernetes, définissez des requests (ressources garanties) et des limits (ressources maximales) pour CPU et mémoire
* *Memory leaks* : Surveillez activement les fuites mémoire qui peuvent causer des redémarrages fréquents
* *JVM tuning* : Pour les applications Java, configurez correctement le heap size et le garbage collector en fonction des ressources allouées
* *Connection pools* : Dimensionnez correctement vos pools de connexions (DB, HTTP clients) en fonction du nombre d'instances et de la charge
* *Thread pools* : Configurez les thread pools pour éviter l'épuisement des threads et les blocages

== Développement local et environnement de dev

====
Développer localement, c'est répéter en studio: on règle les fausses notes avant le concert en prod.
====

Développer pour le cloud ne signifie pas que tout doit se faire dans le cloud. Un bon environnement de développement local est crucial :

=== Émulation locale des services cloud

* *LocalStack* : Émule les services AWS localement (S3, DynamoDB, SQS, etc.)
* *Azurite* : Émulateur pour Azure Storage
* *Docker Compose* : Orchestrez localement vos services (base de données, cache, message queues)
* *Testcontainers* : Lancez des conteneurs pour vos tests d'intégration
* *Minikube/Kind* : Exécutez Kubernetes localement pour tester vos déploiements

=== Configuration locale vs cloud

* Utilisez des profils de configuration différents pour le développement local vs cloud
* Évitez de dépendre de services cloud spécifiques pendant le développement local quand possible
* Documentez clairement les étapes pour configurer l'environnement de développement local
* Utilisez des variables d'environnement avec des valeurs par défaut pour simplifier la configuration locale

=== Hot reload et développement rapide

* Utilisez des outils de hot reload (Spring Boot DevTools, Nodemon, Air pour Go) pour accélérer le cycle de développement
* Configurez des volumes montés dans Docker pour un rechargement rapide du code
* Utilisez des outils comme Skaffold ou Tilt pour le développement continu sur Kubernetes

== Tests pour applications cloud natives

====
Les tests, c'est comme les crashs tests de voitures : on fracasse des prototypes dans un labo pour éviter d'avoir de vrais accidents sur l'autoroute. Et quand quelqu'un modifie le volant ou les freins, on refracasse tout pour vérifier que ça tient toujours la route.
====

Tester des applications cloud nécessite une approche différente :

=== Tests unitaires

* Tests isolés de la logique métier
* Mockez les dépendances externes (base de données, services tiers)
* Utilisez des frameworks de test adaptés à votre langage

=== Tests d'intégration

* *Testcontainers* : Lancez des conteneurs Docker pour tester avec de vraies dépendances
* *Tests de base de données* : Testez les requêtes SQL et les migrations avec une vraie base de données
* *Tests d'API* : Testez vos endpoints REST/gRPC avec des outils comme RestAssured, Supertest

=== Tests end-to-end

* Testez le système complet dans un environnement similaire à la production
* Utilisez des outils comme Selenium, Cypress, Playwright pour les applications web
* Automatisez ces tests dans votre pipeline CI/CD

=== Tests de charge et de performance

* *Load testing* : Testez le comportement sous charge normale (Apache JMeter, Gatling, k6)
* *Stress testing* : Testez les limites du système
* *Spike testing* : Testez la réponse à des pics soudains de trafic
* *Soak testing* : Testez la stabilité sur une longue période pour détecter les fuites mémoire

=== Tests de chaos engineering

* Testez la résilience en introduisant des défaillances volontaires
* Utilisez des outils comme Chaos Monkey, Gremlin, ou LitmusChaos
* Simulez des pannes de serveurs, des latences réseau, des bases de données indisponibles

=== Tests de régression visuelle

* Pour les applications frontend, testez que l'interface n'a pas changé de façon non intentionnelle
* Utilisez des outils comme Percy, Chromatic, ou Applitools

== Communication entre services

====
La communication entre services, c'est comme un orchestre de jazz : chaque musicien doit savoir quand jouer, dans quelle tonalité, et à quel tempo. Sans protocole commun (REST, gRPC, ou messages asynchrones), c'est la cacophonie. Tout le monde improvise, mais pendant le même jam-session.
====

Si votre application est composée de plusieurs microservices :

* *API REST* : Standard et simple, utilisez HTTP/HTTPS avec des formats JSON.
* *gRPC* : Plus performant que REST, utilise Protocol Buffers et HTTP/2.
* *Message queues* : Pour la communication asynchrone, utilisez RabbitMQ, Apache Kafka, AWS SQS, Azure Service Bus, Postgres Notify, ou GCP Pub/Sub.
* *Service mesh* : Pour gérer la communication entre services (Istio, Linkerd) avec features comme le load balancing, le circuit breaking, et le mTLS.

Considérations importantes :

* Utilisez des timeouts pour toutes les communications inter-services
* Implémentez des retry avec backoff exponentiel
* Utilisez des circuit-breakers pour éviter les cascades de défaillances
* Propagez les correlation IDs pour le tracing distribué

=== Résilience et gestion des erreurs

====
La résilience, c'est l'amortisseur: la route est cahoteuse, mais on garde le cap sans casser le châssis.
====

Dans un environnement distribué, les erreurs sont inévitables. Votre application doit être conçue pour être résiliente :

* *Circuit breaker* : Évite de surcharger un service défaillant en "ouvrant le circuit" après un certain nombre d'échecs.
* *Retry avec backoff exponentiel* : Réessaie les opérations échouées avec un délai croissant entre chaque tentative.
* *Timeout* : Définissez des timeouts pour toutes les opérations réseau pour éviter d'attendre indéfiniment.
* *Bulkhead* : Isolez les ressources pour qu'une défaillance dans une partie du système n'affecte pas les autres.
* *Fallback* : Prévoyez un comportement de secours quand une opération échoue (cache, valeur par défaut, mode dégradé).

Des bibliothèques comme Resilience4j (Java), Polly (.NET) ou Hystrix facilitent l'implémentation de ces patterns.

=== Patterns de conception cloud natifs

====
Les bons patterns, c'est une carte routière: on évite les chemins de terre et on arrive à l'heure.
====

Plusieurs patterns architecturaux sont particulièrement adaptés au cloud :

* *Strangler Fig Pattern* : Migrez progressivement une application monolithique vers des microservices en "étranglant" l'ancien système
* *Backend for Frontend (BFF)* : Créez des API spécifiques pour chaque type de client (web, mobile, etc.)
* *API Gateway* : Point d'entrée unique pour tous vos services, gérant l'authentification, le routage, le rate limiting
* *Event Sourcing* : Stockez tous les changements d'état comme une séquence d'événements
* *CQRS (Command Query Responsibility Segregation)* : Séparez les opérations de lecture et d'écriture pour optimiser chacune indépendamment
* *Sidecar Pattern* : Déployez des fonctionnalités auxiliaires (logging, monitoring) dans un conteneur séparé mais adjacent

=== Anti-patterns à éviter

====
Les anti-patterns, ce sont les panneaux ‘route barrée': si on insiste, on finit dans le fossé.
====

* *Distributed Monolith* : Microservices trop couplés qui doivent être déployés ensemble
* *Chatty Services* : Trop de communication entre services, créant de la latence
* *Data Ownership Violations* : Services accédant directement à la base de données d'autres services
* *Ignorer la loi de fallacies of distributed computing* : Supposer que le réseau est fiable, la latence nulle, la bande passante infinie, etc.


== Sécurité

====
La sécurité, c'est la serrure ET l'alarme: le cloud a des voisins curieux, mieux vaut être prudent.
====

La sécurité est une responsabilité partagée par les développeurs et l'équipe devops doit être intégrée dès le début :

* *Principe du moindre privilège* : Donnez uniquement les permissions nécessaires aux applications et aux utilisateurs.
* *Encryption* : Chiffrez les données au repos et en transit (TLS/HTTPS).
* *Authentification et autorisation* : Utilisez des standards comme OAuth2/OIDC pour l'authentification, JWT pour les tokens.
* *Scan de vulnérabilités* : Scannez régulièrement vos dépendances et vos images.
* *WAF* : Utilisez un Web Application Firewall pour protéger contre les attaques courantes.
* *DDoS protection* : Activez la protection DDoS offerte par votre cloud provider.
* *Audit logs* : Conservez des logs d'audit pour toutes les opérations sensibles.

== Environnements multiples

====
Multi-environnements, ce sont des costumes adaptés: même comédien, répétitions en studio, première en gala.
====

Maintenez plusieurs environnements pour différents stades du cycle de vie :

* *Développement* : Pour le développement local et les tests rapides
* *Test/QA* : Pour les tests d'intégration et d'acceptation
* *Staging/Pre-prod* : Une copie de la production pour les tests finaux
* *Production* : L'environnement de production

Utilisez l'Infrastructure as Code pour garantir que tous les environnements sont configurés de manière cohérente.

== Conclusion

====
Adopter ces pratiques, c'est comme apprendre le piano : on ne joue pas du Beethoven dès le premier jour. Commencez par les bases, adaptez à votre rythme, et avant longtemps vous ferez de la musique — sans péter les plombs ni le budget.
====

Développer pour le cloud n'est pas simplement une question de déploiement dans un fournisseur cloud.
Il faut penser à certains aspects spécifiques du développement pour s'assurer que l'application fonctionne correctement dans un environnement distribué.

Ce petit guide couvre plusieurs des considérations les plus importantes, mais il en existe d'autres en fonction des besoins spécifiques de chaque application.
Il n'est certes pas exhaustif, mais j'espère qu'il servira de point de départ pour ceux qui débutent dans le développement cloud natif.

L'adoption de ces pratiques peut sembler lourde au début, mais elle apporte de nombreux avantages : meilleure scalabilité, résilience accrue, facilité de maintenance, et réduction des coûts à long terme. L'important est de commencer progressivement et d'adapter ces principes aux besoins réels de votre application.

Si vous voulez aller plus loin, les principes des https://12factor.net/[12-Factor App], une méthodologie bien établie pour construire des applications SaaS (Software as a Service) modernes est un bon point de départ.
