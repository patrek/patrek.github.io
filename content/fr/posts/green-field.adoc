---
date : '2025-01-13T00:00:00-05:00'
draft : true
title : Démarrage d'un nouveau projet en terrain vierge
description: Les projets, bibliothèques, outils et pratiques que j'ai remarqués
featured_image : "/images/greenfield.jpg"
summary: Une liste de projets, bibliothèques, outils et pratiques que j'utiliserais si je démarrais un projet à partir de rien
toc: true
---

= Projet champ vierge
:sectnums:
:toc: left

[[introduction]]
== Je rêve
Je rêve du jour où je serais invité à participer à un projet depuis son inception, pour être capable de décider ce qui y entrerait et ce qui n'y entrerait pas. Être capable de choisir les technologies, l'architecture, les pratiques, les outils, les processus, les méthodologies, l'équipe même.

À l'époque où j'ai commencé à programmer pour un emploi, beaucoup des technologies que nous considérons comme acquises aujourd'hui n'existaient même pas. C'est comme si j'avais grandi avec l'évolution de certaines technologies, appris de mes erreurs. J'ai essayé différentes alternatives pour le même besoin et j'ai expérimenté où certaines sont meilleures que d'autres.

Depuis longtemps, je suis principalement un développeur Java. Quand j'ai commencé, je savais programmer, mais pas sur la Programmation Orientée Objet. Ma première expérience en Java était d'aider un projet à mon anciens élèves. Je ne savais pas vraiment ce qu'était une classe, ni comment la compiler, mais je pouvais échapper aux caractères spéciaux afin qu'un servlet puisse créer du javascript qui créerait du html qui se compilerait et fonctionnerait. Je ai beaucoup appris depuis. Je dois reconnaître que j'ai commencé ce voyage par [Big Java](https://horstmann.com/bigjava/).

Alors plongeons directement dedans. Je vais lister les technologies, pratiques, outils, processus, méthodologies, membres de l'équipe , etc. que j'aimerais avoir dans mon projet de terrain vierge.

== Ne pas réinventer la roue

En tant que principe directeur, je ne réinventerais pas la roue. J'utiliserais des technologies, pratiques, outils, processus, méthodologies, membres de l'équipe, etc. qui existent déjà.

Rares sont les cas où nous devons inventer quelque chose de nouveau. La plupart du temps, nous pouvons utiliser quelque chose qui existe déjà. C'est plus rapide, moins cher et plus fiable.

J'appelle cela **Se tenir sur les épaules de géants**.

== Conventions

=== https://www.conventionalcommits.org/en/v1.0.0/[Conventional Commits]

Il y a quelque temps, j'ai découvert la spécification des Conventional Commits. C'est une convention simple sur la façon d'écrire des messages de commit. C'est simple, mais c'est puissant. Cela nous permet de générer des journaux de modifications, des versions des numéros, etc. automatiquement.

Avec une convention définie, il est plus facile pour chacun dans l'équipe de comprendre ce qu'est un commit à propos. Cela facilite également la génération de notes de version.

Un message de commit typique ressemblerait à ceci :

```
feat: permettre à l'objet de configuration fourni d'étendre d'autres configurations

Ferme: JIRA-1234
```

```
<type>[portée optionnelle]: <description>

[corps optionnel]

[pied(s) de page optionnel(s)]
```

Le type peut être l'un des suivants :

* feat : Une nouvelle fonctionnalité
* fix : Un correctif
* build : Changements qui affectent le système de construction ou les dépendances externes
* chore : Changements qui ne modifient pas les fichiers src ou test
* ci : Changements apportés à nos fichiers de configuration CI et scripts
* docs: Changements uniquement dans la documentation
* style: Changements qui n'affectent pas le sens du code (espaces, formatage, point-virgule manquant	deux-points, etc)
* refactor: Un changement de code qui ne corrige ni un bug ni n'ajoute une fonctionnalité
* perf: Amélioration des performances
* test: Ajout de tests manquants ou correction de tests existants

Dans le pied de page, j'ajouterais une référence au ticket JIRA (ou tout autre système de tickets) auquel le commit est lié.

En allant un peu plus loin, je pense que le type devrait également être le préfixe pour le nom de la branche. Suivi de le numéro de ticket, et enfin quelques mots sur la fonctionnalité ou le problème. De cette façon, nous pouvons facilement voir de quoi il s'agit dans la branche.

.exemple
```
feat/JIRA-1234-permettre-objet-config-fourni-d'étendre-autres-configs
```

=== https://semver.org/[Semantic versioning]

J'utiliserais le versionnement sémantique pour versionner le projet. C'est une convention simple qui nous permet de savoir quel type de changements se trouvent dans une version rien qu'en regardant le numéro de version.

Traduction de la définition depuis celle du site web semver :
```
Étant donné un numéro de version MAJOR.MINOR.PATCH, incrémentez le :

la version MAJOR lorsque vous apportez des modifications API incompatibles
la version MINOR lorsque vous ajoutez des fonctionnalités de manière rétrocompatible la version PATCH lorsque vous effectuez des corrections de bogues rétrocompatibles

Des étiquettes supplémentaires pour les métadonnées de pré-version et de construction sont disponibles en tant qu'extensions à le format MAJOR.MINOR.PATCH.
```

.exemples
```
1.0.0
2.1.3
4.1.3ALPHA
```

En ce qui concerne la version, ce ne sont que des chiffres, nous ne devrions pas hésiter à les incrémenter, ils ne coûtent rien. Et nous ne devrions pas essayer de garder toutes les parties d'un projet synchronisées avec le numéro de version. Il est acceptable d'avoir une version 1.0.0 d'une bibliothèque et une version 2.0.0 de l'application qui l'utilise.

Mais, lorsque nous déployons, nous devons garder une trace des versions des différentes parties du projet. Cela nous permet de voir facilement ce qui est déployé où.

== Documentation

Nous devons colliger les informations et documenter divers aspects de notre projet.
Toute la documentation n'a pas besoin d'être au même endroit. Il est souvent préférable de garder la documentation près du code pour s'assurer qu'elle reste à jour.

Cependant, nous avons également besoin d'un endroit central pour indexer toute la documentation. Un wiki est une bonne solution pour cet aspect.

=== Diataxis

J'ai récemment été introduit au concept de Diataxis (https://dev.to/onepoint/documentation-chaotique-diataxis-a-la-rescousse--3e9o).

C'est une façon de catégoriser et d'organiser la documentation d'un projet.

On peut le voir comme une matrice avec deux axes : le contenu et la forme.

|===
|si le contenu décrit |et permet au lecteur de |alors cela devrait être une forme de

|actions
|acquérir des compétences
|tutoriel

|actions
|appliquer des compétences
|guide pratique

|connaissances
|acquérir des connaissances
|explication de concepts

|connaissances
|appliquer les connaissances
|références
|===

=== Format https://asciidoctor.org/[asciidoctor]

Il existe de nombreuses façons et formats pour documenter notre futur projet. Très souvent, nous verrons markdown comme format. Malheureusement, markdown est plus limité, et il existe une variété de saveurs pour markdown.

Donc, nous devrions utiliser Asciidoc comme format. C'est un format puissant qui peut être utilisé pour créer de la documentation. Il peut être utilisé pour générer de la documentation dans de nombreux formats, comme html, pdf, etc. La documentation peut être pour différentes sorties, comme un livre, un article, etc.

Si nous devons un jour le convertir à nouveau en markdown, nous pouvons utiliser la commande suivante :

.Conversion d'asciidoctor à markdown
```bash
asciidoctor -b docbook -a leveloffset=+1 -o - green-field.adoc| pandoc --wrap=preserve-t markdown_strict -f docbook - > green-field2.md
```

== Développement

=== IDE (Environnement de Développement Intégré)

J'adore IntelliJ IDEA de jetbrains. Je l'utilise depuis longtemps (depuis décembre 2012). Mais en fait, chaque personne devrait utiliser n'importe quel IDE qu'elle aime, à une condition : *Ils devraient le maîtriser*. Ils devraient savoir comment l'utiliser à son plein potentiel.

Si nous avons une personne junior dans notre équipe, assurez-vous qu'elle prenne le temps d'apprendre son IDE.

=== Projet de services auxiliaires (docker-compose)

Dans de nombreux projets, nous aurons besoin de certains services auxiliaires. J'utiliserais docker-compose pour définir les services auxiliaires. Et envelopper les actions dans un script shell qui offre une aide et des valeurs par défaut raisonnables.

De cette façon, nous pouvons démarrer les services auxiliaires avec une seule commande. Nous pouvons également arrêter les services avec une seule commande. Nous pouvons également redémarrer les services auxiliaires avec une seule commande.

Dans nos projets, le script d'aide comprend des profils. Ainsi, un développeur front-end commencerait par l'aide des services comme la base de données et le backend, tandis qu'un développeur backend commencerait par la base de données et le front-end. Et un QA commencerait tout.

* Page d'aide en libre-service. C'est une simple page html qui est servie par les services d'aide. Elle contient des informations sur les services d'aide, comme la version, les points de terminaison, la documentation, etc. Nous utilisons https://github.com/caddyserver/caddy-docker[caddy] pour cela, et un volume local pour servir la page html.
* https://traefik.io/traefik/[traefik] comme un proxy inverse pour toutes nos applications
	** Nous pouvons le configurer avec un basculement. De cette façon, même si nous avons commencé avec un profil spécifique, disons 		dites backend, nous pouvons toujours démarrer le backend localement et cela prendra le pas sur celui 		dans le fichier docker-compose.
	** https: traefik nous permet d'utiliser https avec une configuration simple. Cela peut provenir d'un certificat let’s 	encrypt, ou d'un certificat auto-signé, ou en utilisant le .
* https://www.portainer.io/products/portainer-platform-universal-container-management-platform[portainer] pour gérer nos conteneurs sans se soucier de la plateforme que nos développeurs ou qa utilisent
* traduction des jetons JWT avec https://jwt.io/[jwt.io]
	** Si nous utilisons un jeton JWT, nous devrons souvent extraire les informations de ceux-ci. Nous pouvons utiliser 			jwt.io pour cela. C'est un outil simple qui peut être utilisé pour extraire les informations d'un JWT 			token. Mais, si nous avons peur de la fuite d'informations, nous pouvons également utiliser une version locale de 			jwt.io.
* postgresql ou autre base de données
* serveur keycloak si nécessaire
* grafana : dans notre cas, nous utilisons grafana pour afficher aux utilisateurs
* rabbitmq : dans notre cas, nous utilisons rabbitmq pour gérer les messages et les files d'attente entre les 	différents services
* wiremock : dans notre cas, nous utilisons wiremock pour simuler des services externes
* https://dozzle.dev/[dozzle], pour voir les journaux des conteneurs
* https://github.com/mailhog/MailHog[mailhog] pour voir les e-mails envoyés par l'application, c'est un simple serveur smtp qui peut être utilisé pour 	voir les e-mails envoyés par l'application
* une sorte de service de surveillance

Nous pouvons également ajouter tout autre service d'assistance qui peut être dockerisé.

Et bien sûr, tous les projets, modules ou microservices qui font partie du projet.

* front end
* back end
* passerelle api
* etc.

=== Langages

==== Backend : Java

Comme je l'ai dit au début, je suis développeur Java de métier et d'expérience. J'utiliserais Java pour construire le backend du projet. C'est un langage mature. C'est un langage puissant qui a de nombreuses fonctionnalités comme la programmation orientée objet, la programmation fonctionnelle, etc. Il existe également de nombreux frameworks et bibliothèques matures qui ont été développés par des experts dans leurs domaines.

Bien sûr, d'autres langages pourraient être utilisés, comme Kotlin, Scala, Groovy, etc. Mais je resterais avec Java.

==== Frontend

Pour le frontend, j'aurais du mal à choisir entre React et Angular. React a beaucoup de momentum en ce moment, mais je n'ai pas beaucoup d'expérience avec. D'un autre côté, on me dit qu'ils y a beaucoup d'extensions qui servent le même but, donc il n'est pas clair quel est le bon chemin. Le jury est toujours en délibération sur celui-ci.

=== Formatage du code

La simple réalité est de choisir un, n'importe lequel et de s'y tenir.
Mais, d'après mon expérience, j'ajouterais d'autres critères pour le sélectionner :

* Défini par une entité bien connue (ne perdez pas de temps à débattre si vous devez mettre des accolades à la 	fin de la ligne ou sur la ligne suivante)
* Facile à utiliser (vous ne devriez pas avoir à y penser)
* Peut être vérifié automatiquement par vos pipelines
* Peut être appliqué automatiquement par votre IDE
* Est orienté (il ne devrait pas y avoir beaucoup de configurations que vous pouvez lui appliquer)

==== Base de code Java : https://github.com/google/google-java-format[Google java format]

Pour le code Java, j'utiliserais Google Java Format. C'est défini par Google, donc c'est une entité bien connue. C'est facile à utiliser, et cela formatera notre code. Il peut être vérifié automatiquement par nos pipelines et appliqué automatiquement par notre IDE.

==== Formatage du code Javascript/Typescript : https://prettier.io/[Prettier]

Je ne sais pas grand-chose sur le formatage du code Javascript. J'utiliserais les mêmes critères que pour le formatage du code Java. Prettier semble être un bon candidat.

=== Système de tickets et de problèmes

Dès qu'il y a (ou pourrait y avoir) plus d'une personne travaillant sur un projet, nous aurons besoin d'un moyen pour gérer notre travail, notez que les tâches à accomplir, etc. Nous devrions utiliser le système de tickets qui est déjà en place dans l'organisation où le projet a commencé. S'il n'y en a pas, de nombreuses options sont disponibles.

* https://www.atlassian.com/software/jira[Atlassian Jira]
* https://www.jetbrains.com/youtrack/[Jetbrains Youtrack]
* https://www.zoho.com/projects/[Zoho Projects]
* https://github.com/features/issues[Github Issues]
* https://gitlab.com[Gitlab Issues]

=== Messages d'erreur : utiliser l'API des problèmes RFC 9457

Lorsque nous construisons une API, nous devrons renvoyer des messages d'erreur. Il est agréable si nous pouvons prédéfinir le format des messages d'erreur et être cohérents dans toutes les APIs que nous exposons, même si seulement en interne.

J'utiliserais le _Problem Details for HTTP APIs_ (https://datatracker.ietf.org/doc/rfc9457/[RFC 9457]) pour renvoyer des messages d'erreur. C'est une simple convention qui peut être utilisée pour renvoyer des messages d'erreur. Elle peut être utilisée pour renvoyer des messages d'erreur dans de nombreux formats, comme json, xml, etc. Elle peut être utilisée pour renvoyer des messages d'erreur dans de nombreux langages, comme java, javascript, etc.

.exemple d'API de problèmes
```json
{
"statut": 500,
"titre": "Erreur interne du serveur",
"uuid": "d79f8cfa-ef5b-4501-a2c4-8f537c08ec0c", "application": "super-microservice",
"version": "1.0"
}
```

Une caractéristique à noter est que nous pouvons faire en sorte que l'erreur dans les journaux ait un UUID unique qui est également renvoyé au client. De cette façon, nous pouvons tracer l'erreur dans les journaux et dans le client.

Voici un article plus long par _A java geek_ qui explique https://blog.frankel.ch/problem-details-http-apis/

Il existe une implémentation prête pour Quarkus : https://github.com/quarkiverse/quarkus-resteasy-problem

=== Système de chat

La communication est essentielle dans un projet. Que ce soit pour une question rapide, pour partager un extrait de code, pour demander de l'aide, etc. Nous avons besoin d'un système de chat.

Ici encore, j'utiliserais le système de chat qui est déjà en place dans l'organisation où le projet est lancé. S'il n'y en a pas, de nombreuses options comme MS Teams, Slack, etc. sont disponibles.

S'assurer que nous créons des canaux dédiés pour différents aspects (code, révision, déploiements/devops, amusant) du projet. De cette façon, nous pouvons garder la conversation ciblée sur le bon sujet.

=== Revue de code

La revue de code est une bonne pratique à mettre en place. Cela aide à avoir un code de qualité et à partager des connaissances. Nous devrions avoir nos blocs de pipeline si le code n'est pas revu.

=== Exemples de code sélectionnés

J'identifierais dans la base de code des exemples de bon code. De cette façon, lorsqu'un nouveau développeur rejoint le équipe, il peut voir ce qui est considéré comme un bon code. Cela peut être une classe simple, une méthode, un modèle, etc.


=== Tests unitaires et d'intégration

Mettre en place dès le début du projet la pratique de la rédaction de tests pour les systèmes. Premièrement des tests unitaires pour tester le code et les cas limites, et ensuite, des tests d'intégration pour tester les interactions entre les différentes parties du système là où c'est nécessaires.

Éviter de tester les bibliothèques de code utilisées.

Les tests doivent être exécutés automatiquement à chaque fois que le code est modifié et avant qu'il ne soit fusionné.

== Cadres et bibliothèques

=== https://quarkus.io/[Quarkus]

J'utiliserais Quarkus comme cadre pour construire le backend du projet. C'est un Java moderne cadre qui est assez mature. On dirait qu'il a été construit dès le départ avec le développeur en tête. Et il peut créer des artefacts qui sont natifs, rapides et adaptés aux conteneurs.

Il existe un excellent tutoriel pour nous donner un aperçu du cadre et des fonctionnalités associées. https://quarkus.io/quarkus-workshops/super-heroes/

=== https://mapstruct.org/[Mapstruct]

Très souvent, lors de la construction d'un backend robuste, nous aurons besoin de différents modèles mais correspondants (DTO, pojo, entités) pour différentes parties de l'application.

À mesure que l'information passe d'une partie de l'application à une autre (de la base de données au service, du service au contrôleur, du contrôleur au client), nous devrons mapper les informations d'un modèle à un autre.

J'utiliserais Mapstruct. C'est un produit puissant qui peut être utilisé pour mapper des objets d'un type à un autre. Le mapping se fait à la compilation, donc c'est rapide.

C'est assez utile quand nous devons mapper d'un DTO à une entité et vice versa. Il peut faire correspondre les propriétés par nom, ou nous pouvons définir le mapping nous-mêmes. Nous pouvons également facilement définir des transformations personnalisées au besoin.

=== https://projectlombok.org/[Lombok]

L'une des plaintes que les gens ont sur Java est d'écrire beaucoup de code standard. J'utiliserais Lombok pour alléger cela. C'est un produit puissant qui peut être utilisé pour générer le code standard pour nous. Il peut être utilisé pour générer le code de base pour nous de plusieurs manières, comme les accesseurs, les mutateurs, les constructeurs, y compris certains modèles comme les constructeurs, equals et hashcode, etc.

Pour certaines constructions, utiliser les https://www.baeldung.com/java-record-keyword[Records] de java pourrait être une bonne alternative.

=== https://www.liquibase.com/[Liquibase]

À un certain moment, nous aurons probablement besoin d'une base de données relationnelle pour stocker nos données (voir Postgresql plus tard à ce sujet). Et ensuite, nous aurons besoin d'un moyen de gérer le schéma de cette base de données. J'utiliserais Liquibase pour cela. C'est un produit mature qui peut être utilisé pour gérer le schéma de la base de données. Il peut être utilisé pour créer le schéma, mettre à jour le schéma, etc. Il peut également être utilisé pour créer des données dans la base de données.

Il prend également en charge le concept de contextes. Ainsi, nous pouvons stocker dans le même système différents ensembles de modifications pour différents environnements, besoins ou fonctionnalités. C'est une fonctionnalité puissante.

Il y a même un certain support pour certaines bases de données non relationnelles/sql, comme MongoDB, Noe4j, Databricks Data Lakehouses, etc.

=== https://opentelemetry.io/[OpenTelemetry]

Surveiller notre application est souvent une tâche qui est repoussée dans le futur, après que les fonctionnalités soient mises en œuvre. Mais il est important de commencer à y penser tôt. J'utiliserais OpenTelemetry pour surveiller l'application. C'est un moderne cadre qui peut être utilisé pour surveiller l'application. Il peut être utilisé pour surveiller l'application en production, mais aussi en développement. Il peut être utilisé pour surveiller l'application dans un conteneur, mais aussi dans un environnement natif.

Et nous pouvons également ajouter nos propres métriques. Disons que nous voulons surveiller le nombre de fois qu'un fonctionnalité spécifique est utilisée. Nous pouvons ajouter une métrique pour cela. Ou si nous voulons nous assurer qu'un job cron est complété correctement au taux attendu, nous pouvons ajouter une métrique pour cela.

Un exemple de la documentation quarkus :

.https://quarkus.io/guides/opentelemetry-metrics
```java
package org.acme;

import io.opentelemetry.api.metrics.LongCounter;
import io.opentelemetry.api.metrics.Meter;
import jakarta.ws.rs.GET;
import jakarta.ws.rs.Path;
import jakarta.ws.rs.Produces;
import jakarta.ws.rs.core.MediaType;
import org.jboss.logging.Logger;

@Path("/hello-metrics")
public class MetricResource {

    private static final Logger LOG = Logger.getLogger(MetricResource.class);

    private final LongCounter counter;

public MetricResource(Meter meter) {
        counter = meter.counterBuilder("hello-metrics")
                .setDescription("hello-metrics")
                .setUnit("invocations")
 .build();
    }

    @GET
    @Produces(MediaType.TEXT_PLAIN)
    public String hello() {
        counter.add(1);
        LOG.info("hello-metrics");
        return "hello-metrics";
 }
}
```

=== Nous aurons besoin de commutateurs de fonctionnalités

_Que diriez-vous si je vous disais "vous pouvez tout mettre dans des commutateurs de fonctionnalité" ?_

Dès que notre système central existe, nous devrions envisager d'encapsuler chaque fonctionnalité dans des commutateurs de fonctionnalité.

Il y a deux raisons principales à cela :

* Nous pouvons publier une fonctionnalité sans la rendre disponible aux utilisateurs, ce qui facilite la 	livraison continue
* Nous pouvons publier une fonctionnalité à un sous-ensemble d'utilisateurs, afin de pouvoir la tester avec de vrais utilisateurs avant de la publier pour tout le monde. Nous pouvons également rendre la fonctionnalité disponible sur différents plans d'abonnement, etc. Enfin, nous pouvons également utiliser des commutateurs de fonctionnalité pour désactiver une fonctionnalité si elle ne fonctionne pas comme prévu.

Nous pouvons également utiliser des commutateurs de fonctionnalité pour désactiver une fonctionnalité si elle ne fonctionne pas comme prévu.

==== https://openfeature.dev/[OpenFeature]

En recherchant pour cet article, je suis tombé sur OpenFeature. C'est un service de commutateurs de fonctionnalités gratuit spécification qui peut être implémentée par n'importe quel service.

En utilisant les SDK openfeature, nous pouvons éviter le verrouillage des fournisseurs et avoir une manière cohérente de gérer nos drapeaux de fonctionnalités.

==== https://www.getunleash.io/[Unleash]

Unleash propose une version gratuite que nous pouvons utiliser pour commencer. Nous pouvons le déployer sur notre propre infrastructure.

Il y a une discussion sur le fait de faire en sorte qu'unleash prenne en charge la spécification openfeature, mais ce n'est pas encore implémenté.

== Outils et services

=== https://www.postgresql.org/[Postgresql] [[postgresql]]

Si notre projet nécessite une base de données relationnelle, j'utiliserais Postgresql. C'est un produit mature qui peut être utilisé pour stocker les données du projet. C'est un produit puissant qui a de nombreuses fonctionnalités comme les transactions, les contraintes, les déclencheurs, etc. Il a de nombreuses capacités intégrées, comme le stockage d'objets en json format, la recherche en texte intégral, etc. Il a également de nombreux , comme Postgis, qui peuvent être utilisés pour stocker et interroger des données géospatiales, TimescaleDB, qui peut être utilisé pour stocker et interroger des données de séries temporelles, etc. Il est très stable et a une grande communauté.


==== https://www.timescale.com/[TimescaleDB] Données de séries temporelles

Si jamais nous rencontrons une situation où nous devons stocker des données de séries temporelles, j'utiliserais TimescaleDB. C'est une extension de Postgresql qui peut être utilisée pour stocker et interroger des données de séries temporelles. C'est un produit puissant et performant qui possède de nombreuses fonctionnalités comme le regroupement temporel, les agrégats continus, etc. C'est un produit puissant qui peut être utilisé pour stocker et interroger des données de séries temporelles.

=== https://www.keycloak.org/[Keycloak]

À un moment donné, nous devrons gérer les utilisateurs et leur accès à l'application. J'utiliserais Keycloak pour cela. C'est un produit mature qui peut être utilisé pour gérer les utilisateurs, les rôles, les permissions, etc. Nous pouvons également le configurer pour différer l'authentification à un système externe en utilisant des fournisseurs d'identité. Il existe même un moyen de migrer nos utilisateurs d'un système externe vers Keycloak.

=== https://www.wiremock.io/[Wiremock]

Il est tout à fait possible que notre projet doive interagir avec des services externes. Nous voudrons tester notre code sans avoir à dépendre de l'appel réel de ces services externes. J'utiliserais Wiremock pour cela. C'est un produit mature qui peut simuler les services externes. Nous pouvons définir les réponses que nous voulons obtenir des services externes et utiliser Wiremock pour simuler les services externes. Il prend même en charge la randomisation du résultat ou le retour de timestamps qui sont toujours une période définie dans le passé ou le futur de l'appel.

=== Gestion des mots de passe

Nous avons des mots de passe, trop d'entre eux. Et nous ne devrions pas les stocker en texte clair. J'utiliserais un gestionnaire de mots de passe pour stocker les mots de passe. Il existe de nombreux gestionnaires de mots de passe disponibles, comme 1Password, LastPass, Bitwarden, etc.

Certains, comme 1Password, sont plus qu'un simple coffre-fort de mots de passe, ils viennent avec des outils qui nous permettent d'utiliser en toute sécurité les mots de passe dans nos applications ou sur la ligne de commande.

== https: Let’s Encrypt ou localhost.direct

De nos jours, le web est censé être sécurisé. Nous devrions utiliser https. Nous pouvons utiliser https://letsencrypt.org/[Let's Encrypt] pour obtenir un certificat gratuit. Mais, si nous travaillons dans un environnement local, nous pouvons utiliser  pour obtenir un certificat gratuit pour notre environnement local.

== Commit

=== https://git-scm.com/[Git] and repository

Puisque nous parlons finalement d'écrire du code en équipe, nous avons besoin d'un moyen de gérer notre code. Je choisirais Git comme système de contrôle de version. Ensuite, nous aurions besoin d'un endroit pour stocker ce code. Le suspects habituels sont Github, Gitlab, Bitbucket, etc.

Je serais pragmatique et choisirais ce qui est déjà utilisé dans l'organisation où le projet est commencé. Tant que nous pouvons également avoir des pipelines pour vérifier, construire et empaqueter le code, ça me va.

==== https://github.com/frace/git-passport[Git passport]

Si nous travaillons sur plusieurs projets, où le code est stocké dans différents dépôts, nous pourrions veut utiliser git passport. C'est un outil qui nous permet de gérer plusieurs identités git.

==== https://github.com/git-ecosystem/git-credential-manager[Git Credential Manager]

Nous travaillerons probablement sur plus d'un projet à un moment donné, et nous devrons gérer nos identifiants. J'utiliserais Git Credential Manager pour gérer mes identifiants. C'est un outil puissant qui peut être utilisé pour gérer nos identifiants. Il peut être utilisé pour gérer nos identifiants de plusieurs manières, comme les stocker de manière sécurisée, les partager avec notre équipe, etc. Il peut également être utilisé pour gérer nos identifiants dans de nombreux environnements, comme le développement, la qa, la mise en scène, l'uat, la production.

=== https://getsops.io/[Sops]

À un moment donné, c'est sûr, nous devrons gérer des secrets dans notre dépôt. J'utiliserais Sops pour chiffrer ces secrets. De cette façon, je peux les stocker dans le dépôt git sans craindre qu'ils soient lu par des personnes qui ne devraient pas avoir accès.
Assurez-vous que nous incluons cela tôt dans le processus, afin qu'aucun secret ne soit jamais stocké en texte clair dans notre dépôt. (Voir l'article correspondant)

=== https://gitlab.com[Gitlab] ou autre dépôt de code

Certaines organisations utilisent Gitlab, d'autres utilisent Github, Bitbucket ou même AWS CodeCommit. Quoi que votre organisation utilise, assurez-vous d'avoir un pipeline qui peut vérifier, construire et empaqueter le code. Assurez-vous d'avoir un pipeline qui peut déployer le code. Assurez-vous d'avoir un pipeline qui peut surveiller le code. Assurez-vous d'avoir un pipeline qui peut revenir en arrière sur le code.

== CI (Intégration continue)

=== Gitlab CI / Pipelines

Comme nous utilisons Gitlab, nous utiliserons les pipelines qui peuvent s'exécuter dans gitlab. C'est un outil puissant qui peut être utilisé pour vérifier, construire et empaqueter le code. Il peut être utilisé pour déployer le code. Il peut être utilisé pour surveiller le code. Il peut être utilisé pour revenir en arrière sur le code.

Voici quelques étapes typiques que nous mettons dans nos pipelines :

* pré-valider : utiliser <<dangerjs>> pour vérifier les messages de commit et s'assurer qu'ils respectent les 	conventions que nous avons établies avec l'équipe.
* vérifier le format : assurez-vous que le code est correctement formaté. Comme nous ne voulons pas donner les droits de commit du pipeline, nous ne formatons pas le code, mais nous vérifions qu'il est correctement formaté.
* compiler : assurez-vous que le code se compile correctement. C'est une étape simple qui peut être effectuée rapidement.
* test unitaire : exécutez des tests unitaires pour le code
* installer : installez le code java dans le dépôt local maven
* test d'intégration : s'ils existent, exécutez le test d'intégration.
* rapport de couverture de code : générez le rapport de couverture de code. Cela peut être fait avec JaCoCo, ou tout autre 	outil de couverture de code.
* analyse statique : exécutez une analyse statique sur le code. Cela peut être fait avec Sonarqube, ou tout autre 	outil d'analyse statique.
* scan sat : exécutez l'outil satscan sur le code. Cela peut être fait avec l'outil satscan.
* image(s) docker : créez l'image docker de l'application ou du module. Si nous utilisons le 	modèle mono-repo, il peut y avoir plusieurs images docker à construire ici.
* post-validation : encore avec le cadre danger. Typiquement ici, nous vérifions si le nombre approprié 	d'approbations existe.

===  https://danger.systems/js/[Danger] [[dangerjs]]

Traduction libre du site web de danger :
```
Danger s'exécute pendant votre processus CI, et donne aux équipes la chance d'automatiser les tâches de révision de code tâches de révision.

Cela fournit une autre étape logique dans votre construction, à travers cela Danger peut aider à lint vos tâches répétitives dans la révision quotidienne du code.

Vous pouvez utiliser Danger pour codifier les normes de vos équipes. Laisser les humains réfléchir à des problèmes plus difficiles .

Cela se produit par Danger laissant des messages dans vos PRs basés sur des règles que vous créez avec JavaScript ou TypeScript.

Au fil du temps, à mesure que les règles sont respectées, le message est modifié pour refléter l'état actuel de la révision du code.
```

=== https://www.sonarsource.com/products/sonarqube/[Sonarqube]

Nous voudrons vérifier la qualité de notre code. L'analyse statique de notre code permet de détecter de nombreux problèmes. habitudes, bugs ou problèmes de sécurité.

J'utiliserais Sonarqube pour cela. C'est un produit mature qui peut vérifier notre code pour des bugs, vulnérabilités, mauvaises pratiques de code, etc. Il peut également vérifier notre code pour la couverture, les duplications, etc.

La plupart des IDE devraient avoir un plugin afin que nous puissions voir les résultats de l'analyse directement dans notre IDE ou avant de valider.

== Déploiement

=== Images et conteneurs Docker

Je pense qu'il est raisonnable de penser que nous déploierons notre application dans des conteneurs. D'autant plus si notre application n'est pas un gros monolithe, mais un ensemble de modules ou de microservices. Pensez à faire un front end en React, un backend en Quarkus, une base de données en Postgresql, etc. Nous pouvons utiliser Docker pour créer les images de notre application. Nous pouvons utiliser Docker pour exécuter les conteneurs de notre application. Et, si le besoin se présente, nous pouvons utiliser Kubernetes pour déployer l'ensemble de notre pile d'application.

Donc, tôt dans le projet, assurez-vous que nous avons un pipeline qui peut construire les images de notre application. Et testez-le.

Idéalement, nous devrions avoir un pipeline qui construit les images, et les pousser vers un dépôt de conteneurs. Cela nous permet d'utiliser la même image dans tous nos environnements.

Je pense que faire une image différente pour chaque environnement est une mauvaise idée. Nous devrions être capables de déployer la même image dans tous nos environnements. La seule différence devrait être la configuration.

Nous nous épargnerons beaucoup de douleur et de stress si nous commençons tôt avec cela au lieu d'attendre de le faire quand nous sommes près du Test d'Acceptation Utilisateur ou pire, de la date de Production.

=== https://www.terraform.io/[Terraform] pour l'infrastructure en tant que code

Nous allons déployer notre application dans une sorte d'infrastructure. Et nous aurons très probablement besoin de la même infrastructure dans différents environnements, comme le développement, la qa, la mise en scène, l'uat, la production. Le meilleur moyen de s'assurer que chaque environnement est aussi proche que possible du précédent est de le rendre reproductible. J'utiliserais Terraform pour définir l'infrastructure en tant que code. De cette façon, nous pouvons déployer la même infrastructure dans chaque environnement.

=== https://terragrunt.gruntwork.io//[Terragrunt] pour aider à rendre Terraform un peu plus gérable

Terragrunt est un mince wrapper pour Terraform qui fournit des outils supplémentaires pour garder vos configurations DRY, travailler avec plusieurs modules Terraform, et gérer l'état distant.

Gérer une grande infrastructure avec Terraform est un peu douloureux. Nous avons probablement un gros fichier d'état sur le bucket AWS S3. Nous avons probablement beaucoup de modules. Nous avons probablement beaucoup d'environnements. Terragrunt peut nous aider à gérer tout cela.

== Surveillance des projets

À un moment donné, nous devrons surveiller notre application d'une manière ou d'une autre. Je suis actuellement en train de chercher chez Signoz, mais je n'ai pas vraiment d'option préférée ou recommandée pour le moment.

* https://signoz.io/[Signoz]
* https://www.elastic.co/apm/[Elastic APM]
* https://www.jaegertracing.io/[Jaeger]
* https://prometheus.io/[Prometheus]
* https://skywalking.apache.org/[Apache Skywalking]
** https://github.com/apache/skywalking/blob/master/docker/docker-compose.yml
* https://pinpoint-apm.github.io/pinpoint/[Pinpoint]
* https://www.stagemonitor.org/[Stagemonitor]

=== https://github.com/plausible/community-edition/[plausible] pour les données analytiques

Je considère cela comme un sous-ensemble de la surveillance. Nous voudrons probablement savoir si nos utilisateurs utilisent notre application. Nous voudrons probablement savoir comment ils utilisent notre application. Nous voudrons probablement savoir d'où ils viennent. J'utiliserais Plausible pour cela. C'est un produit simple qui peut être utilisé pour surveiller notre application. Il peut être utilisé pour surveiller notre application en production, mais aussi en développement. Il peut être utilisé pour surveiller notre application dans un conteneur, mais aussi dans un environnement natif.

== Autres projets à explorer

*  pour la capture de données de changement
*  pour l'audit des changements de ligne
*  pour l'audit des changements

